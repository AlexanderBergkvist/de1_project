{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "import nltk\n",
    "import json\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ta bort\n",
    "#confSpark = SparkConf().set(\"spark.driver.bindAddress\", \"localhost\")\n",
    "#sc = SparkContext(\"local[*]\", \"appname\", conf = confSpark)\n",
    "\n",
    "\"\"\"# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.119:7077\") \\\n",
    "        .appName(\"TestApp\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"INFO\")\"\"\"\n",
    "conf = SparkConf()\n",
    "conf.setMaster('spark://192.168.2.119:7077')\n",
    "conf.setAppName('YEEHAW2')\n",
    "spark_context = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"rdd = spark_context.newAPIHadoopFile(\n",
    "    'RC_2005-12',\n",
    "    'org.apache.hadoop.mapreduce.lib.input.TextInputFormat',\n",
    "    'org.apache.hadoop.io.LongWritable',\n",
    "    'org.apache.hadoop.io.Text'\n",
    ")\\\n",
    ".cache()\"\"\"\n",
    "#hdfs://localhost:9000\n",
    "rdd = spark_context.newAPIHadoopFile(\n",
    "    'hdfs://localhost:9000/user/ubuntu/RC_2010-06',\n",
    "    'org.apache.hadoop.mapreduce.lib.input.TextInputFormat',\n",
    "    'org.apache.hadoop.io.LongWritable',\n",
    "    'org.apache.hadoop.io.Text'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '{\"ups\":0,\"author_flair_css_class\":null,\"body\":\"Amazon is a great starting point\",\"gilded\":0,\"subreddit\":\"photography\",\"downs\":0,\"archived\":true,\"score_hidden\":false,\"retrieved_on\":1426326692,\"score\":0,\"author\":\"indecisive11\",\"author_flair_text\":null,\"id\":\"c0r5eac\",\"edited\":false,\"controversiality\":0,\"subreddit_id\":\"t5_2qh2a\",\"distinguished\":null,\"name\":\"t1_c0r5eac\",\"created_utc\":\"1275350400\",\"parent_id\":\"t3_ca1vs\",\"link_id\":\"t3_ca1vs\"}')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_groups = dict()\n",
    "gram_groups['Adjectives'] = ['JJ', 'JJR', 'JJS']\n",
    "gram_groups['Nouns'] = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "gram_groups['Pronouns'] = ['PRP', 'PRP$']\n",
    "gram_groups['Adverbs'] = ['RB', 'RBR', 'RBS']\n",
    "gram_groups['Verb'] = ['VB', 'VBG', 'VBD', 'VBN', 'VBP', 'VBZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_body(rdd):\n",
    "    body = rdd\\\n",
    "    .map(lambda line: json.loads(line[1])['body'].strip().split())\\\n",
    "\n",
    "    return body\n",
    "\n",
    "def check_gram_grp(tag_tuple):\n",
    "    word, tag = tag_tuple\n",
    "    for supergroup, subgroups in gram_groups.items():\n",
    "                if tag in subgroups:\n",
    "                    return supergroup\n",
    "    return None\n",
    "\n",
    "def categorize_words(split_rdd):\n",
    "    cat_words = split_rdd.flatMap(lambda word: nltk.pos_tag(word))\\\n",
    "    .map(lambda tupl: (check_gram_grp(tupl), 1))\\\n",
    "    .filter(lambda x: x[0] != None)\n",
    "   \n",
    "    return cat_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = get_split_body(rdd)\n",
    "categorized = categorize_words(split)\n",
    "group_counts = categorized.reduceByKey(add).collect()\n",
    "print(group_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = sum([gram_grp[1] for gram_grp in group_counts])\n",
    "group_counts_norm = [(x[0], x[1]/total) for x in group_counts]\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the grammatical classes\n",
    "import matplotlib.pyplot as plt\n",
    "grammatical_group = []\n",
    "numbers = []\n",
    "for gram_group, num in group_counts:\n",
    "    grammatical_group.append(gram_group)\n",
    "    numbers.append(num)\n",
    "    \n",
    "plt.plot(grammatical_group,numbers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divided with the total\n",
    "gram_procentage = []\n",
    "for num in numbers:\n",
    "    gram_procentage.append(num/total)\n",
    "\n",
    "plt.plot(grammatical_group,gram_procentage)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En annan variant av plot ifall vi vill ha bar ist√§llet /Oscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.bar(list(zip(*group_counts))[0], list(zip(*group_counts))[1], color='Orange')\n",
    "plt.grid(axis='y')\n",
    "plt.xlabel('Grammatical Group')\n",
    "plt.ylabel('Normalized frequency')\n",
    "plt.title(f'Total amount of categorized words: {total}',fontsize=10)\n",
    "plt.suptitle(\"Frequency of words in grammatical groups\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
