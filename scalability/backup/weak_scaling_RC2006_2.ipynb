{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Two workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "import nltk\n",
    "import json\n",
    "from time import time\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tstart_stack = []\n",
    "def tic():\n",
    "    _tstart_stack.append(time())\n",
    "def toc(fmt=\"Elapsed: %s s\"):\n",
    "    print (fmt % (time() - _tstart_stack.pop()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_groups = dict()\n",
    "gram_groups['Adjectives'] = ['JJ', 'JJR', 'JJS']\n",
    "gram_groups['Nouns'] = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "gram_groups['Pronouns'] = ['PRP', 'PRP$']\n",
    "gram_groups['Adverbs'] = ['RB', 'RBR', 'RBS']\n",
    "gram_groups['Verb'] = ['VB', 'VBG', 'VBD', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "def get_split_body(rdd):\n",
    "    body = rdd\\\n",
    "    .map(lambda line: json.loads(line[1])['body'].strip().split())\\\n",
    "    \n",
    "    return body\n",
    "\n",
    "def check_gram_grp(tag_tuple):\n",
    "    word, tag = tag_tuple\n",
    "    for supergroup, subgroups in gram_groups.items():\n",
    "                if tag in subgroups:\n",
    "                    return supergroup\n",
    "    return None\n",
    "\n",
    "def categorize_words(split_rdd):\n",
    "    cat_words = split_rdd.flatMap(lambda word: nltk.pos_tag(word))\\\n",
    "    .map(lambda tupl: (check_gram_grp(tupl), 1))\\\n",
    "    .filter(lambda x: x[0] != None)\n",
    "   \n",
    "    return cat_words\n",
    "\n",
    "def final_test(rdd):\n",
    "    split = get_split_body(rdd)\n",
    "    categorized = categorize_words(split)\n",
    "    group_counts = categorized.reduceByKey(add).collect()\n",
    "    return group_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (8 cores, 16gb per machine) x 5 = 40 cores\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.119:7077\") \\\n",
    "        .appName(\"ScalibilityTest_\")\\\n",
    "        .config(\"spark.executor.memory\", \"2g\")\\\n",
    "        .getOrCreate()\n",
    "# Old API (RDD)\n",
    "#        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "#        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "\n",
    "spark_context = spark_session.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conf = SparkConf()\n",
    "#conf.setMaster('spark://192.168.2.119:7077')\n",
    "#conf.setAppName('Strong_Scalibility')\n",
    "#spark_context = SparkContext(conf=conf)\n",
    "#spark_context.setLogLevel(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark_context.newAPIHadoopFile(\n",
    "    'hdfs://localhost:9000/user/ubuntu/RC_2006-02',\n",
    "    'org.apache.hadoop.mapreduce.lib.input.TextInputFormat',\n",
    "    'org.apache.hadoop.io.LongWritable',\n",
    "    'org.apache.hadoop.io.Text'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '{\"created_utc\":1138752114,\"author_flair_css_class\":null,\"score\":0,\"ups\":0,\"subreddit\":\"reddit.com\",\"stickied\":false,\"link_id\":\"t3_15xh\",\"subreddit_id\":\"t5_6\",\"body\":\"THAN the title suggests.  Whoops.\",\"controversiality\":1,\"retrieved_on\":1473820870,\"distinguished\":null,\"gilded\":0,\"id\":\"c166b\",\"edited\":false,\"parent_id\":\"t3_15xh\",\"author\":\"gmcg\",\"author_flair_text\":null}')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDD  info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9095\n"
     ]
    }
   ],
   "source": [
    "n = rdd.count()\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "np = rdd.getNumPartitions()\n",
    "print(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd6 = rdd.repartition(6)\n",
    "rdd6.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9095"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd6.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = rdd.take(1)[0][1]\n",
    "#json.loads(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an rdd with half size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_2_3 = rdd6.sample(False, 2/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 23.275262594223022 s\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "final_test(rdd6)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test with half data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 14.650781869888306 s\n"
     ]
    }
   ],
   "source": [
    "tic()\n",
    "final_test(rdd_2_3)\n",
    "toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
